<!doctype html>














<!-- `site.alt_lang` can specify a language different from the UI -->
<html lang="en" data-mode="dark">
  <!-- custom-head.html -->
<!-- ✅ Google AdSense site verification -->

<meta name="google-adsense-account" content="ca-pub-4795027126021575">





<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7">
  <meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e">
  <meta name="mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta
    name="viewport"
    content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover"
  ><!-- Setup Open Graph image -->

  

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<meta name="generator" content="Jekyll v4.4.1" />
<meta property="og:title" content="10-(4) Transformer 모델은 Seq2Seq 구조와 어떤 점에서 근본적으로 다른가요?" />
<meta name="author" content="Soohyun Chris Jeon" />
<meta property="og:locale" content="en" />
<meta name="description" content="🟢 Transformer 모델은 Seq2Seq 구조와 어떤 점에서 근본적으로 다른가요? 앞서 설명한 attention 매커니즘은 구조적인 측면에서 RNN을 사용한다는 점은 동일했다. 즉, 기존 seq2seq 모델에 추가적인 attention modeule을 추가한 형태라고 한다면 Transformer는 아예 새로운 아키텍처라고 보면 되겠다. 즉," />
<meta property="og:description" content="🟢 Transformer 모델은 Seq2Seq 구조와 어떤 점에서 근본적으로 다른가요? 앞서 설명한 attention 매커니즘은 구조적인 측면에서 RNN을 사용한다는 점은 동일했다. 즉, 기존 seq2seq 모델에 추가적인 attention modeule을 추가한 형태라고 한다면 Transformer는 아예 새로운 아키텍처라고 보면 되겠다. 즉," />
<link rel="canonical" href="http://localhost:4000/posts/Transformer/" />
<meta property="og:url" content="http://localhost:4000/posts/Transformer/" />
<meta property="og:site_name" content="Serendipity" />
<meta property="og:image" content="https://gaussian37.github.io/assets/img/dl/concept/transformer/2.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-08-08T14:00:00+09:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://gaussian37.github.io/assets/img/dl/concept/transformer/2.png" />
<meta property="twitter:title" content="10-(4) Transformer 모델은 Seq2Seq 구조와 어떤 점에서 근본적으로 다른가요?" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Soohyun Chris Jeon"},"dateModified":"2025-09-04T18:16:04+09:00","datePublished":"2025-08-08T14:00:00+09:00","description":"🟢 Transformer 모델은 Seq2Seq 구조와 어떤 점에서 근본적으로 다른가요? 앞서 설명한 attention 매커니즘은 구조적인 측면에서 RNN을 사용한다는 점은 동일했다. 즉, 기존 seq2seq 모델에 추가적인 attention modeule을 추가한 형태라고 한다면 Transformer는 아예 새로운 아키텍처라고 보면 되겠다. 즉,","headline":"10-(4) Transformer 모델은 Seq2Seq 구조와 어떤 점에서 근본적으로 다른가요?","image":"https://gaussian37.github.io/assets/img/dl/concept/transformer/2.png","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/posts/Transformer/"},"url":"http://localhost:4000/posts/Transformer/"}</script>
<!-- End Jekyll SEO tag -->


  <title>10-(4) Transformer 모델은 Seq2Seq 구조와 어떤 점에서 근본적으로 다른가요? | Serendipity
  </title>

  <!--
  The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps
  Generated by: https://realfavicongenerator.net/
-->



<link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png">

  <link rel="manifest" href="/assets/img/favicons/site.webmanifest">

<link rel="shortcut icon" href="/assets/img/favicons/favicon.ico">
<meta name="apple-mobile-web-app-title" content="Serendipity">
<meta name="application-name" content="Serendipity">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml">
<meta name="theme-color" content="#ffffff">


  <!-- Resource Hints -->
  
    
      
        <link rel="preconnect" href="https://fonts.googleapis.com" >
      
        <link rel="dns-prefetch" href="https://fonts.googleapis.com" >
      
    
      
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
      
        <link rel="dns-prefetch" href="https://fonts.gstatic.com" >
      
    
      
        <link rel="preconnect" href="https://cdn.jsdelivr.net" >
      
        <link rel="dns-prefetch" href="https://cdn.jsdelivr.net" >
      
    
  

  <!-- Bootstrap -->
  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.6/dist/css/bootstrap.min.css">
  

  <!-- Theme style -->
  <link rel="stylesheet" href="/assets/css/jekyll-theme-chirpy.css">

  <!-- Web Font -->
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400&family=Source+Sans+Pro:wght@400;600;700;900&display=swap">

  <!-- Font Awesome Icons -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.7.1/css/all.min.css">

  <!-- 3rd-party Dependencies -->

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.32.2/dist/tocbot.min.css">
  

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/loading-attribute-polyfill@2.1.1/dist/loading-attribute-polyfill.min.css">
  

  
    <!-- Image Popup -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/glightbox@3.3.0/dist/css/glightbox.min.css">
  

  <!-- Scripts -->

  <script src="/assets/js/dist/theme.min.js"></script>

  <!-- JS selector for site. -->

<!-- commons -->



<!-- layout specified -->


  

  
    <!-- image lazy-loading & popup & clipboard -->
    
  















  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  



  <script defer src="https://cdn.jsdelivr.net/combine/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js,npm/loading-attribute-polyfill@2.1.1/dist/loading-attribute-polyfill.umd.min.js,npm/glightbox@3.3.0/dist/js/glightbox.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js,npm/dayjs@1.11.13/dayjs.min.js,npm/dayjs@1.11.13/locale/en.js,npm/dayjs@1.11.13/plugin/relativeTime.js,npm/dayjs@1.11.13/plugin/localizedFormat.js,npm/tocbot@4.32.2/dist/tocbot.min.js"></script>







<script defer src="/assets/js/dist/post.min.js"></script>



<!-- Pageviews -->

  

  



  

  <!-- A placeholder to allow defining custom metadata -->

</head>

  <body>
    <!-- The Side Bar -->

<aside aria-label="Sidebar" id="sidebar" class="d-flex flex-column align-items-end">
  <header class="profile-wrapper">
    <a href="/" id="avatar" class="rounded-circle"><img src="/assets/img/Siamese-Cat.PNG" width="112" height="112" alt="avatar" onerror="this.style.display='none'"></a>

    <a class="site-title d-block" href="/">Serendipity</a>
    <p class="site-subtitle fst-italic mb-0">나는 생각하는 감자</p>
  </header>
  <!-- .profile-wrapper -->

  <nav class="flex-column flex-grow-1 w-100 ps-0">
    <ul class="nav">
      <!-- home -->
      <li class="nav-item">
        <a href="/" class="nav-link">
          <i class="fa-fw fas fa-home"></i>
          <span>HOME</span>
        </a>
      </li>
      <!-- the real tabs -->
      
        <li class="nav-item">
          <a href="/categories/" class="nav-link">
            <i class="fa-fw fas fa-stream"></i>
            

            <span>CATEGORIES</span>
          </a>
        </li>
        <!-- .nav-item -->
      
        <li class="nav-item">
          <a href="/tags/" class="nav-link">
            <i class="fa-fw fas fa-tags"></i>
            

            <span>TAGS</span>
          </a>
        </li>
        <!-- .nav-item -->
      
        <li class="nav-item">
          <a href="/archives/" class="nav-link">
            <i class="fa-fw fas fa-archive"></i>
            

            <span>ARCHIVES</span>
          </a>
        </li>
        <!-- .nav-item -->
      
        <li class="nav-item">
          <a href="/about/" class="nav-link">
            <i class="fa-fw fas fa-info-circle"></i>
            

            <span>ABOUT</span>
          </a>
        </li>
        <!-- .nav-item -->
      
    </ul>
  </nav>

  <div class="sidebar-bottom d-flex flex-wrap  align-items-center w-100">
    

    
      

      
        <a
          href="https://github.com/soohyun-chris-jeon"
          aria-label="github"
          

          
            target="_blank"
            
          

          

          
            rel="noopener noreferrer"
          
        >
          <i class="fab fa-github"></i>
        </a>
      
    
      

      
        <a
          href="https://instagram.com/jssseh"
          aria-label="instagram"
          

          
            target="_blank"
            
          

          

          
            rel="noopener noreferrer"
          
        >
          <i class="fab fa-instagram"></i>
        </a>
      
    
      

      
        <a
          href="mailto:jssseh@gmail.com"
          aria-label="custom"
          

          
            target="_blank"
            
          

          

          
            rel="noopener noreferrer"
          
        >
          <i class="fas fa-envelope"></i>
        </a>
      
    
      

      
        <a
          href="/feed.xml"
          aria-label="rss"
          

          
            target="_blank"
            
          

          

          
            rel="noopener noreferrer"
          
        >
          <i class="fas fa-rss"></i>
        </a>
      
    
  </div>
  <!-- .sidebar-bottom -->
</aside>
<!-- #sidebar -->


    <div id="main-wrapper" class="d-flex justify-content-center">
      <div class="container d-flex flex-column px-xxl-5">
        <!-- The Top Bar -->

<header id="topbar-wrapper" class="flex-shrink-0" aria-label="Top Bar">
  <div
    id="topbar"
    class="d-flex align-items-center justify-content-between px-lg-3 h-100"
  >
    <nav id="breadcrumb" aria-label="Breadcrumb">
      

      
        
          
            <span>
              <a href="/">Home</a>
            </span>

          
        
          
        
          
            
              <span>10-(4) Transformer 모델은 Seq2Seq 구조와 어떤 점에서 근본적으로 다른가요?</span>
            

          
        
      
    </nav>
    <!-- endof #breadcrumb -->

    <button type="button" id="sidebar-trigger" class="btn btn-link" aria-label="Sidebar">
      <i class="fas fa-bars fa-fw"></i>
    </button>

    <div id="topbar-title">
      Post
    </div>

    <button type="button" id="search-trigger" class="btn btn-link" aria-label="Search">
      <i class="fas fa-search fa-fw"></i>
    </button>

    <search id="search" class="align-items-center ms-3 ms-lg-0">
      <i class="fas fa-search fa-fw"></i>
      <input
        class="form-control"
        id="search-input"
        type="search"
        aria-label="search"
        autocomplete="off"
        placeholder="Search..."
      >
    </search>
    <button type="button" class="btn btn-link text-decoration-none" id="search-cancel">Cancel</button>
  </div>
</header>


        <div class="row flex-grow-1">
          <main aria-label="Main Content" class="col-12 col-lg-11 col-xl-9 px-md-4">
            
              <!-- Refactor the HTML structure -->



<!--
  In order to allow a wide table to scroll horizontally,
  we suround the markdown table with `<div class="table-wrapper">` and `</div>`
-->



<!--
  Fixed kramdown code highlight rendering:
  https://github.com/penibelst/jekyll-compress-html/issues/101
  https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901
-->



<!-- Change the icon of checkbox -->



<!-- Handle images -->




  
  

  
    
      
      
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    
      

      
      
      

      
    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  

  


<!-- Add header for code snippets -->



<!-- Create heading anchors -->





  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    

    
  

  
  

  

  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    

    
  

  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      
    

    
  




<!-- return -->










<article class="px-1" data-toc="true">
  <header>
    <h1 data-toc-skip>10-(4) Transformer 모델은 Seq2Seq 구조와 어떤 점에서 근본적으로 다른가요?</h1>
    

    <div class="post-meta text-muted">
      <!-- published date -->
      <span>
        Posted
        <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
  data-ts="1754629200"
  data-df="ll"
  
    data-bs-toggle="tooltip" data-bs-placement="bottom"
  
>
  Aug  8, 2025
</time>

      </span>

      <!-- lastmod date -->
      
        <span>
          Updated
          <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
  data-ts="1756977364"
  data-df="ll"
  
    data-bs-toggle="tooltip" data-bs-placement="bottom"
  
>
  Sep  4, 2025
</time>

        </span>
      

      
        
        
        

        

        <div class="mt-3 mb-3">
          <a href="https://gaussian37.github.io/assets/img/dl/concept/transformer/2.png" class="popup img-link preview-img shimmer"><img src="https://gaussian37.github.io/assets/img/dl/concept/transformer/2.png"  alt="Preview Image" width="1200" height="630"  loading="lazy"></a></div>
      

      <div class="d-flex justify-content-between">
        <!-- author(s) -->
        <span>
          

          By

          <em>
            
              <a href="https://github.com/soohyun-chris-jeon">soohyun-chris-jeon</a>
            
          </em>
        </span>

        <div>
          <!-- pageviews -->
          

          <!-- read time -->
          <!-- Calculate the post's reading time, and display the word count in tooltip -->



<!-- words per minute -->










<!-- return element -->
<span
  class="readtime"
  data-bs-toggle="tooltip"
  data-bs-placement="bottom"
  title="1465 words"
>
  <em>8 min</em> read</span>

        </div>
      </div>
    </div>
  </header>

  
    <div id="toc-bar" class="d-flex align-items-center justify-content-between invisible">
      <span class="label text-truncate">10-(4) Transformer 모델은 Seq2Seq 구조와 어떤 점에서 근본적으로 다른가요?</span>
      <button type="button" class="toc-trigger btn me-1">
        <i class="fa-solid fa-list-ul fa-fw"></i>
      </button>
    </div>

    <button id="toc-solo-trigger" type="button" class="toc-trigger btn btn-outline-secondary btn-sm">
      <span class="label ps-2 pe-1">Contents</span>
      <i class="fa-solid fa-angle-right fa-fw"></i>
    </button>

    <dialog id="toc-popup" class="p-0">
      <div class="header d-flex flex-row align-items-center justify-content-between">
        <div class="label text-truncate py-2 ms-4">10-(4) Transformer 모델은 Seq2Seq 구조와 어떤 점에서 근본적으로 다른가요?</div>
        <button id="toc-popup-close" type="button" class="btn mx-1 my-1 opacity-75">
          <i class="fas fa-close"></i>
        </button>
      </div>
      <div id="toc-popup-content" class="px-4 py-3 pb-4"></div>
    </dialog>
  

  <div class="content">
    <h2 id="-transformer-모델은-seq2seq-구조와-어떤-점에서-근본적으로-다른가요"><span class="me-2">🟢 Transformer 모델은 Seq2Seq 구조와 어떤 점에서 근본적으로 다른가요?</span><a href="#-transformer-모델은-seq2seq-구조와-어떤-점에서-근본적으로-다른가요" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p>앞서 설명한 attention 매커니즘은 구조적인 측면에서 RNN을 사용한다는 점은 동일했다. 즉, 기존 seq2seq 모델에 추가적인 attention modeule을 추가한 형태라고 한다면 <strong>Transformer는 아예 새로운 아키텍처</strong>라고 보면 되겠다. 즉,</p>

<ul>
  <li>(1세대) RNN 기반의 기본 Seq2Seq</li>
  <li>(2세대) RNN 기반 Seq2Seq + Attention (성능 개선)</li>
  <li>(3세대) Transformer (RNN을 완전히 대체한 새로운 구조)</li>
</ul>

<p align="center">
  <a href="https://miro.medium.com/1*tb9TT-mwFn1WPzkkbjoMCQ.png
  " class="popup img-link shimmer"><img src="https://miro.medium.com/1*tb9TT-mwFn1WPzkkbjoMCQ.png
  " alt="attention" width="80%" style="display: block; margin: 0 auto;" loading="lazy"></a>
</p>

<p>그래서 지금부터는 현재 AI 산업의 가장 큰 축인 LLM의 핵심 아키텍처인 Transformer에 대해서 알아보겠다.</p>

<hr />

<h4 id="-seq2seq-vs-transformer"><span class="me-2">⚪ Seq2Seq vs Transformer</span><a href="#-seq2seq-vs-transformer" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>
<p>전통적인 Seq2Seq 모델이 <strong>RNN(순환 신경망)</strong>을 사용해 데이터를 <strong>순차적으로(sequentially)</strong> 처리하는 반면, Transformer는 <strong>RNN을 완전히 제거</strong>하고 <strong>Self-Attention</strong>이라는 메커니즘을 사용해 데이터를 <strong>병렬적으로(in parallel)</strong> 처리함.</p>

<hr />

<h4 id="-데이터-처리-방식-순차적-vs-병렬적"><span class="me-2">⚪ 데이터 처리 방식: 순차적 vs. 병렬적</span><a href="#-데이터-처리-방식-순차적-vs-병렬적" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<ul>
  <li>
    <p><strong>Seq2Seq (RNN 기반)</strong>
  RNN은 단어를 <strong>하나씩 순서대로</strong> 처리. 첫 번째 단어를 처리한 결과를 바탕으로 두 번째 단어를 처리하고, 그 결과를 바탕으로 세 번째 단어를 처리하는 식. 이런 순차적인 구조 때문에 <strong>병렬 처리가 불가능</strong>해서 학습 속도가 느림.</p>
  </li>
  <li>
    <p><strong>Transformer</strong>
  Transformer는 Self-Attention을 통해 문장 내 모든 단어를 <strong>한 번에 동시에</strong> 바라봄. 각 단어가 문장 내 다른 모든 단어와 어떤 관계를 맺고 있는지 병렬적으로 계산함. 이 덕분에 GPU의 병렬 연산 능력을 최대한 활용할 수 있어서 <strong>학습 속도가 비약적으로 빨라짐</strong>.</p>
  </li>
</ul>

<hr />

<h4 id="-장기-의존성long-term-dependency-처리"><span class="me-2">⚪ 장기 의존성(Long-Term Dependency) 처리</span><a href="#-장기-의존성long-term-dependency-처리" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<ul>
  <li>
    <p><strong>Seq2Seq (RNN 기반)</strong>
  문장이 길어지면 문장 앞부분의 정보가 뒤로 갈수록 희석되거나 소실되는 <strong>장기 의존성 문제</strong>에 취약했음. 정보가 여러 단계를 거치면서 전달되다 보니 병목 현상이 생김</p>
  </li>
  <li>
    <p><strong>Transformer</strong>
  Self-Attention은 문장의 처음과 끝에 있는 단어라도 <strong>직접적인 연결</strong>을 통해 한 번에 관계를 계산해. 아무리 멀리 떨어진 단어라도 정보 전달 경로가 짧고 직접적이기 때문에 <strong>장기 의존성 문제를 매우 효과적으로 해결</strong>함.</p>
  </li>
</ul>

<hr />

<h5 id="-위치-정보-처리-방식"><span class="me-2">⚪ 위치 정보 처리 방식</span><a href="#-위치-정보-처리-방식" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h5>

<ul>
  <li>
    <p><strong>Seq2Seq (RNN 기반)</strong>
  단어를 순서대로 입력받는 구조 자체가 단어의 순서 정보를 자연스럽게 담고 있음.</p>
  </li>
  <li>
    <p><strong>Transformer</strong>
  모든 단어를 한 번에 처리하기 때문에 모델이 단어의 순서를 알 수 없음. 그래서 <strong>Positional Encoding</strong>이라는 별도의 장치를 사용해 “이 단어는 문장의 n번째 위치에 있다”라는 위치 정보를 인위적으로 주입해 줘야 함.</p>
  </li>
</ul>

<hr />

<h2 id="-핵심-차이점-요약"><span class="me-2">🟢 핵심 차이점 요약</span><a href="#-핵심-차이점-요약" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<div class="table-wrapper"><table>
  <thead>
    <tr>
      <th style="text-align: left">특징 (Feature)</th>
      <th style="text-align: left">Seq2Seq (RNN-based)</th>
      <th style="text-align: left">Transformer</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left"><strong>핵심 엔진</strong></td>
      <td style="text-align: left">RNN (LSTM, GRU)</td>
      <td style="text-align: left">Self-Attention</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>데이터 처리</strong></td>
      <td style="text-align: left">순차적 (Sequential)</td>
      <td style="text-align: left">병렬적 (Parallel)</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>학습 속도</strong></td>
      <td style="text-align: left">느림</td>
      <td style="text-align: left">빠름</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>장기 의존성</strong></td>
      <td style="text-align: left">취약함 (정보 소실)</td>
      <td style="text-align: left">강함 (직접 연결)</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>위치 정보</strong></td>
      <td style="text-align: left">구조에 내재됨</td>
      <td style="text-align: left">Positional Encoding으로 주입</td>
    </tr>
  </tbody>
</table></div>

<p>결론적으로, Transformer는 RNN의 순차적 처리라는 고질적인 한계를 Self-Attention을 통한 병렬 처리로 극복하면서, 더 빠르고 강력하게 문맥을 이해하는 모델로 자리 잡게 되었다.</p>

<p>구글의 <strong>“Attention Is All You Need”</strong>의 논문은 기존 RNN 구조를 버리고 오로지 Attention을 활용한 혁신적인 구조를 제시하면서 현대 NLP의 핵심 요소로 자리잡았고, 어텐션 기반 병렬 처리라는 새로운 패러다임을 열어서 BERT, GPT 같은 현대 NLP 모델들의 기반을 마련했다.</p>

<h2 id="-예시-답안-코드잇-제공"><span class="me-2">🟢 예시 답안 (코드잇 제공)</span><a href="#-예시-답안-코드잇-제공" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<blockquote>

  <ul>
    <li>Transformer 모델은 Seq2Seq 구조와 비교했을 때, 가장 큰 근본적인 차이점은 RNN을 사용하지 않고, 전적으로 Attention 메커니즘만으로 시퀀스를 처리한다는 점입니다.</li>
    <li>전통적인 Seq2Seq 모델은 RNN, LSTM, GRU 같은 순환 신경망 구조를 사용하여 입력 시퀀스를 시간 순서대로 처리합니다. 이 구조는 시간 흐름을 따라 정보를 전달할 수 있지만, 병렬 연산이 어렵고, 긴 시퀀스일수록 학습 속도가 느려지며, 장기 의존성 문제가 발생할 수 있습니다.</li>
    <li>반면 Transformer는 모든 입력 토큰 간의 관계를 한 번에 계산할 수 있는 Self-Attention 메커니즘을 기반으로 동작합니다. 덕분에 각 단어가 문장 내 다른 단어들과 어떻게 연결되는지를 병렬적으로 학습할 수 있으며, 연산 속도가 빠르고, 긴 문장에서도 정보 손실 없이 문맥을 반영할 수 있습니다.</li>
    <li>또한 Transformer는 Positional Encoding이라는 기법을 사용해 입력 토큰의 순서 정보를 보완합니다. 이는 RNN처럼 순차적으로 데이터를 처리하지 않기 때문에 발생할 수 있는 순서 정보 손실 문제를 해결하는 방식입니다.</li>
    <li>결과적으로 Transformer는 Seq2Seq보다 병렬 처리 효율이 뛰어나고, 긴 문장에서도 더 안정적인 성능을 보이며, 기계 번역, 텍스트 요약, 문장 생성 등 다양한 자연어처리 과제에서 기존 Seq2Seq을 대체하고 있습니다.</li>
  </ul>
</blockquote>

  </div>

  <div class="post-tail-wrapper text-muted">
    <!-- categories -->
    
      <div class="post-meta mb-3">
        <i class="far fa-folder-open fa-fw me-1"></i>
        
          <a href="/categories/codeit-ai-3%EA%B8%B0/">Codeit AI 3기</a>,
          <a href="/categories/weekly-paper/">Weekly Paper</a>
      </div>
    

    <!-- tags -->
    
      <div class="post-tags">
        <i class="fa fa-tags fa-fw me-1"></i>
        
          <a
            href="/tags/nlp/"
            class="post-tag no-text-decoration"
          >NLP</a>
        
          <a
            href="/tags/trasnformer/"
            class="post-tag no-text-decoration"
          >Trasnformer</a>
        
          <a
            href="/tags/deep-learning/"
            class="post-tag no-text-decoration"
          >Deep Learning</a>
        
          <a
            href="/tags/ai/"
            class="post-tag no-text-decoration"
          >AI</a>
        
      </div>
    

    <div
      class="
        post-tail-bottom
        d-flex justify-content-between align-items-center mt-5 pb-2
      "
    >
      <div class="license-wrapper">
        
          

          This post is licensed under 
        <a href="https://creativecommons.org/licenses/by/4.0/">
          CC BY 4.0
        </a>
         by the author.
        
      </div>

      <!-- Post sharing snippet -->

<div class="share-wrapper d-flex align-items-center">
  <span class="share-label text-muted">Share</span>
  <span class="share-icons">
    
    
    

    

      

      <a href="https://twitter.com/intent/tweet?text=10-(4)%20Transformer%20%EB%AA%A8%EB%8D%B8%EC%9D%80%20Seq2Seq%20%EA%B5%AC%EC%A1%B0%EC%99%80%20%EC%96%B4%EB%96%A4%20%EC%A0%90%EC%97%90%EC%84%9C%20%EA%B7%BC%EB%B3%B8%EC%A0%81%EC%9C%BC%EB%A1%9C%20%EB%8B%A4%EB%A5%B8%EA%B0%80%EC%9A%94?%20-%20Serendipity&url=http%3A%2F%2Flocalhost%3A4000%2Fposts%2FTransformer%2F" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Twitter" aria-label="Twitter">
        <i class="fa-fw fa-brands fa-square-x-twitter"></i>
      </a>
    

      

      <a href="https://www.facebook.com/sharer/sharer.php?title=10-(4)%20Transformer%20%EB%AA%A8%EB%8D%B8%EC%9D%80%20Seq2Seq%20%EA%B5%AC%EC%A1%B0%EC%99%80%20%EC%96%B4%EB%96%A4%20%EC%A0%90%EC%97%90%EC%84%9C%20%EA%B7%BC%EB%B3%B8%EC%A0%81%EC%9C%BC%EB%A1%9C%20%EB%8B%A4%EB%A5%B8%EA%B0%80%EC%9A%94?%20-%20Serendipity&u=http%3A%2F%2Flocalhost%3A4000%2Fposts%2FTransformer%2F" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Facebook" aria-label="Facebook">
        <i class="fa-fw fab fa-facebook-square"></i>
      </a>
    

      

      <a href="https://t.me/share/url?url=http%3A%2F%2Flocalhost%3A4000%2Fposts%2FTransformer%2F&text=10-(4)%20Transformer%20%EB%AA%A8%EB%8D%B8%EC%9D%80%20Seq2Seq%20%EA%B5%AC%EC%A1%B0%EC%99%80%20%EC%96%B4%EB%96%A4%20%EC%A0%90%EC%97%90%EC%84%9C%20%EA%B7%BC%EB%B3%B8%EC%A0%81%EC%9C%BC%EB%A1%9C%20%EB%8B%A4%EB%A5%B8%EA%B0%80%EC%9A%94?%20-%20Serendipity" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Telegram" aria-label="Telegram">
        <i class="fa-fw fab fa-telegram"></i>
      </a>
    

    <button
      id="copy-link"
      aria-label="Copy link"
      class="btn small"
      data-bs-toggle="tooltip"
      data-bs-placement="top"
      title="Copy link"
      data-title-succeed="Link copied successfully!"
    >
      <i class="fa-fw fas fa-link pe-none fs-6"></i>
    </button>
  </span>
</div>

    </div>
    <!-- .post-tail-bottom -->
  </div>
  <!-- div.post-tail-wrapper -->
</article>


            
          </main>

          <!-- panel -->
          <aside aria-label="Panel" id="panel-wrapper" class="col-xl-3 ps-2 text-muted">
            <div class="access">
              <!-- Get 5 last posted/updated posts -->














  <section id="access-lastmod">
    <h2 class="panel-heading">Recently Updated</h2>
    <ul class="content list-unstyled ps-0 pb-1 ms-1 mt-2">
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/Attention/">10-(3) Attention 메커니즘이 Seq2Seq 모델의 어떤 문제를 해결하는 데 도움이 되나요?</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/Transformer/">10-(4) Transformer 모델은 Seq2Seq 구조와 어떤 점에서 근본적으로 다른가요?</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/YOLO/">8-(1) YOLO(You Only Look Once) 모델의 주요 특징과 장점은 무엇인가요?</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/Generative-model/">생성형 모델(Generative Model)에 대한 이해</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/FastText/">10-(2) FastText가 Word2Vec과 다른 점은 무엇이며, 어떤 장점이 있나요?</a>
        </li>
      
    </ul>
  </section>
  <!-- #access-lastmod -->


              <!-- The trending tags list -->















  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        



  <section>
    <h2 class="panel-heading">Trending Tags</h2>
    <div class="d-flex flex-wrap mt-3 mb-1 me-3">
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/deep-learning/">Deep Learning</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/ai/">AI</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/pytorch/">PyTorch</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/machine-learning/">Machine Learning</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/computer-vision/">Computer Vision</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/cnn/">CNN</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/convolutional-neural-network/">convolutional-neural-network</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/nlp/">NLP</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/python/">python</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/trasnformer/">Trasnformer</a>
      
    </div>
  </section>


            </div>

            
              
              






  <div class="toc-border-cover z-3"></div>
  <section id="toc-wrapper" class="invisible position-sticky ps-0 pe-4 pb-4">
    <h2 class="panel-heading ps-3 pb-2 mb-0">Contents</h2>
    <nav id="toc"></nav>
  </section>


            
          </aside>
        </div>

        <div class="row">
          <!-- tail -->
          <div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 px-md-4">
            
              
              <!-- Recommend the other 3 posts according to the tags and categories of the current post. -->

<!-- The total size of related posts -->


<!-- An random integer that bigger than 0 -->


<!-- Equals to TAG_SCORE / {max_categories_hierarchy} -->















  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  
    
  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  











  <aside id="related-posts" aria-labelledby="related-label">
    <h3 class="mb-4" id="related-label">Further Reading</h3>
    <nav class="row row-cols-1 row-cols-md-2 row-cols-xl-3 g-4 mb-4">
      
        <article class="col">
          <a href="/posts/PEFT/" class="post-preview card h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
  data-ts="1756443600"
  data-df="ll"
  
>
  Aug 29, 2025
</time>

              <h4 class="pt-0 my-2">12-(3) PEFT가 필요한 이유는 무엇이며, 어떤 상황에서 특히 효과적인가요?</h4>
              <div class="text-muted">
                <p>🟢 TBU  ⚪ TBU..  🟢 예시 답안 (코드잇 제공)    PEFT가 필요한 이유는 대형 언어 모델을 실제 환경에 맞게 활용하려고 할 때, 기존의 전체 파인튜닝 방식이 너무 비효율적이고 부담이 크기 때문입니다.기존 방식은 모델의 모든 파라미터를 다시 학습해야 하다 보니, 수많은 GPU 자원이 필요하고, 학습 시간도 오래 걸리며, 각각의 작업마다 ...</p>
              </div>
            </div>
          </a>
        </article>
      
        <article class="col">
          <a href="/posts/model-size/" class="post-preview card h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
  data-ts="1756440000"
  data-df="ll"
  
>
  Aug 29, 2025
</time>

              <h4 class="pt-0 my-2">12-(2) 모델 크기를 키우는 것만으로는 성능이 일정 시점 이후 둔화되는 이유는 무엇일까요?</h4>
              <div class="text-muted">
                <p>🟢 TBU  ⚪ TBU..  🟢 예시 답안 (코드잇 제공)          모델 크기를 키우면 초기에는 성능이 눈에 띄게 좋아지지만, 일정 규모를 넘어서면 성능 향상 속도가 점점 느려지고 결국에는 거의 개선되지 않는 구간에 도달하게 됩니다. 이 현상에는 몇 가지 이유가 있습니다.     첫째, 학습 데이터의 한계입니다. 모델이 아무리 크더라도 학습할 ...</p>
              </div>
            </div>
          </a>
        </article>
      
        <article class="col">
          <a href="/posts/Hallucination/" class="post-preview card h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
  data-ts="1756436400"
  data-df="ll"
  
>
  Aug 29, 2025
</time>

              <h4 class="pt-0 my-2">12-(1) LLM이 생성한 텍스트에서 할루시네이션(Hallucination)이란 무엇이고, 왜 문제가 되나요?</h4>
              <div class="text-muted">
                <p>🟢 LLM이 생성한 텍스트에서 할루시네이션(Hallucination)이란 무엇이고, 왜 문제가 되나요? 여러 LLM 서비스들은 할루시네이션 문제를 어떻게 극복하려고 시도 중일까요? 구글링 등을 통해 자유롭게 리서치해보세요.   ⚪ TBU..  🟢 예시 답안 (코드잇 제공)         LLM이 생성한 텍스트에서 할루시네이션(Hallucination)...</p>
              </div>
            </div>
          </a>
        </article>
      
    </nav>
  </aside>
  <!-- #related-posts -->


            
              
              <!-- Navigation buttons at the bottom of the post. -->

<nav class="post-navigation d-flex justify-content-between" aria-label="Post Navigation">
  
  

  
    <a
      href="/posts/Attention/"
      class="btn btn-outline-primary"
      aria-label="Older"
    >
      <p>10-(3) Attention 메커니즘이 Seq2Seq 모델의 어떤 문제를 해결하는 데 도움이 되나요?</p>
    </a>
  

  
    <a
      href="/posts/part3/"
      class="btn btn-outline-primary"
      aria-label="Newer"
    >
      <p>[Part 3] Study log 2025.08.15 ~ 10.09  </p>
    </a>
  
</nav>

            

            <!-- _includes/footer.html -->
<footer class="custom-footer">
  <p class="left">© 2025 Soohyun Jeon ⭐</p>  <p class="right">🌱 Mostly to remember, sometimes to understand.</p>
</footer>
          </div>
        </div>

        <!-- The Search results -->

<div id="search-result-wrapper" class="d-flex justify-content-center d-none">
  <div class="col-11 content">
    <div id="search-hints">
      <!-- The trending tags list -->















  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        



  <section>
    <h2 class="panel-heading">Trending Tags</h2>
    <div class="d-flex flex-wrap mt-3 mb-1 me-3">
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/deep-learning/">Deep Learning</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/ai/">AI</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/pytorch/">PyTorch</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/machine-learning/">Machine Learning</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/computer-vision/">Computer Vision</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/cnn/">CNN</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/convolutional-neural-network/">convolutional-neural-network</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/nlp/">NLP</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/python/">python</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/trasnformer/">Trasnformer</a>
      
    </div>
  </section>


    </div>
    <div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div>
  </div>
</div>

      </div>

      <aside aria-label="Scroll to Top">
        <button id="back-to-top" type="button" class="btn btn-lg btn-box-shadow">
          <i class="fas fa-angle-up"></i>
        </button>
      </aside>
    </div>

    <div id="mask" class="d-none position-fixed w-100 h-100 z-1"></div>

    
      <aside
  id="notification"
  class="toast"
  role="alert"
  aria-live="assertive"
  aria-atomic="true"
  data-bs-animation="true"
  data-bs-autohide="false"
>
  <div class="toast-header">
    <button
      type="button"
      class="btn-close ms-auto"
      data-bs-dismiss="toast"
      aria-label="Close"
    ></button>
  </div>
  <div class="toast-body text-center pt-0">
    <p class="px-2 mb-3">A new version of content is available.</p>
    <button type="button" class="btn btn-primary" aria-label="Update">
      Update
    </button>
  </div>
</aside>

    

    <!-- Embedded scripts -->

    
      
      <!-- The comments switcher -->


    

    <!--
  Jekyll Simple Search loader
  See: <https://github.com/christian-fei/Simple-Jekyll-Search>
-->





<script>
  
  document.addEventListener('DOMContentLoaded', () => {
    SimpleJekyllSearch({
      searchInput: document.getElementById('search-input'),
      resultsContainer: document.getElementById('search-results'),
      json: '/assets/js/data/search.json',
      searchResultTemplate: '  <article class="px-1 px-sm-2 px-lg-4 px-xl-0">    <header>      <h2><a href="{url}">{title}</a></h2>      <div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1">        {categories}        {tags}      </div>    </header>    <p>{content}</p>  </article>',
      noResultsText: '<p class="mt-5">Oops! No results found.</p>',
      templateMiddleware: function(prop, value, template) {
        if (prop === 'categories') {
          if (value === '') {
            return `${value}`;
          } else {
            return `<div class="me-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`;
          }
        }

        if (prop === 'tags') {
          if (value === '') {
            return `${value}`;
          } else {
            return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`;
          }
        }
      }
    });
  });
</script>

  </body>
</html>
