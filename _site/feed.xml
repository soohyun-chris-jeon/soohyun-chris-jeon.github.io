

<feed xmlns="http://www.w3.org/2005/Atom">
  <id>https://soohyun-chris-jeon.github.io/</id>
  <title>Serendipity</title>
  <subtitle>인공지능과 의료 영상, 그리고 신호처리 연구 내용을 공유하는 블로그입니다. </subtitle>
  <updated>2025-09-05T15:34:31+09:00</updated>
  <author>
    <name>soohyun-chris-jeon</name>
    <uri>https://soohyun-chris-jeon.github.io/</uri>
  </author>
  <link rel="self" type="application/atom+xml" href="https://soohyun-chris-jeon.github.io/feed.xml"/>
  <link rel="alternate" type="text/html" hreflang="en"
    href="https://soohyun-chris-jeon.github.io/"/>
  <generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator>
  <rights> © 2025 soohyun-chris-jeon </rights>
  <icon>/assets/img/favicons/favicon.ico</icon>
  <logo>/assets/img/favicons/favicon-96x96.png</logo>


  
  <entry>
    <title>13-(3) RAG 시스템에서 'Agent'는 어떤 개념인지, 어떻게 구현할 수 있는지 구글 등에서 리서치하여 정리해보세요.</title>
    <link href="https://soohyun-chris-jeon.github.io/posts/RAG2/" rel="alternate" type="text/html" title="13-(3) RAG 시스템에서 &amp;apos;Agent&amp;apos;는 어떤 개념인지, 어떻게 구현할 수 있는지 구글 등에서 리서치하여 정리해보세요." />
    <published>2025-09-05T13:00:00+09:00</published>
  
    <updated>2025-09-05T13:00:00+09:00</updated>
  
    <id>https://soohyun-chris-jeon.github.io/posts/RAG2/</id>
    <content type="text/html" src="https://soohyun-chris-jeon.github.io/posts/RAG2/" />
    <author>
      <name>soohyun-chris-jeon</name>
    </author>

  
    
    <category term="Codeit AI 3기" />
    
    <category term="Weekly Paper" />
    
  

  <summary>🟢 TBU   ⚪ TBU..  🟢 예시 답안 (코드잇 제공)     RAG 시스템에서 ‘Agent’는 단순히 질문에 대한 검색과 답변 생성만 수행하는 고정된 흐름이 아니라, 질문을 이해하고 상황에 따라 필요한 행동을 스스로 결정하며 여러 단계를 유연하게 수행할 수 있는 실행 주체입니다.예를 들어, 일반적인 RAG 시스템은 사용자의 질문을 받으면 관련 문서를 검색하고, 그 내용을 바탕으로 답변을 생성하는 정해진 구조를 따릅니다. 하지만 어떤 질문은 단순하지 않고, 질문을 쪼개거나, 여러 정보를 종합하거나, 추가적인 판단이 필요한 경우가 많습니다. 이럴 때 Agent는 질문의 목적을 이해하고, 어떤 도구를 언제 사용해야 할지 스스로 판단하며, 검색 → 요약 → 비교 → 응답 생성 같은 복합적인 과정을 순차...</summary>

  </entry>

  
  <entry>
    <title>13-(2) RAG 시스템의 성능을 평가하는 방법에는 어떤 것들이 있고, 독립 평가와 종단간 평가의 차이는 무엇인가요?</title>
    <link href="https://soohyun-chris-jeon.github.io/posts/RAG1/" rel="alternate" type="text/html" title="13-(2) RAG 시스템의 성능을 평가하는 방법에는 어떤 것들이 있고, 독립 평가와 종단간 평가의 차이는 무엇인가요?" />
    <published>2025-09-05T11:00:00+09:00</published>
  
    <updated>2025-09-05T11:00:00+09:00</updated>
  
    <id>https://soohyun-chris-jeon.github.io/posts/RAG1/</id>
    <content type="text/html" src="https://soohyun-chris-jeon.github.io/posts/RAG1/" />
    <author>
      <name>soohyun-chris-jeon</name>
    </author>

  
    
    <category term="Codeit AI 3기" />
    
    <category term="Weekly Paper" />
    
  

  <summary>🟢 TBU   ⚪ TBU..  🟢 예시 답안 (코드잇 제공)     RAG 시스템의 성능을 평가할 때는 검색(Retrieval)과 생성(Generation)이라는 두 가지 주요 단계에 대해 각각 또는 전체적으로 성능을 측정해야 합니다. 이때 평가 방식은 크게 독립 평가(모듈별 평가)와 종단간 평가(End-to-End 평가)로 나눌 수 있습니다.먼저 독립 평가는 각 구성 요소의 성능을 분리해서 개별적으로 평가하는 방식입니다. 예를 들어 검색기의 성능은 주어진 질문에 대해 얼마나 관련 있는 문서를 찾아냈는지를 기준으로 평가하며, 대표적으로 Precision@k, Recall@k, MRR(Mean Reciprocal Rank) 같은 검색 기반 지표가 사용됩니다. 생성기 부분은 입력된 문서 기반으로 모델이 얼...</summary>

  </entry>

  
  <entry>
    <title>13-(1) LangChain을 사용해 RAG 시스템을 구축할 때 어떤 주요 구성 요소들이 필요하고, 각각 어떤 역할을 하나요?</title>
    <link href="https://soohyun-chris-jeon.github.io/posts/LangChain/" rel="alternate" type="text/html" title="13-(1) LangChain을 사용해 RAG 시스템을 구축할 때 어떤 주요 구성 요소들이 필요하고, 각각 어떤 역할을 하나요?" />
    <published>2025-09-05T10:00:00+09:00</published>
  
    <updated>2025-09-05T10:00:00+09:00</updated>
  
    <id>https://soohyun-chris-jeon.github.io/posts/LangChain/</id>
    <content type="text/html" src="https://soohyun-chris-jeon.github.io/posts/LangChain/" />
    <author>
      <name>soohyun-chris-jeon</name>
    </author>

  
    
    <category term="Codeit AI 3기" />
    
    <category term="Weekly Paper" />
    
  

  <summary>🟢 TBU   ⚪ TBU..  🟢 예시 답안 (코드잇 제공)     LangChain을 사용해 RAG 시스템을 구축할 때는 몇 가지 핵심 구성 요소들이 필요합니다. 각각의 구성 요소는 시스템 내에서 중요한 역할을 하며, 서로 유기적으로 연결되어 작동합니다.첫 번째로 필요한 건 문서 로더(Document Loader)입니다. 이는 외부에서 정보를 가져오는 역할을 합니다. 예를 들어 PDF, 웹페이지, 텍스트 파일, 데이터베이스 등 다양한 소스에서 문서를 읽어들여 시스템이 활용할 수 있는 형태로 변환합니다.다음은 텍스트 분할기(Text Splitter)입니다. 로딩된 문서가 너무 길면 검색 효율이 떨어지기 때문에, 문서를 일정 길이로 나누는 작업이 필요합니다. 이 과정을 통해 각 문서 조각이 임베딩과 검색...</summary>

  </entry>

  
  <entry>
    <title>12-(3) PEFT가 필요한 이유는 무엇이며, 어떤 상황에서 특히 효과적인가요?</title>
    <link href="https://soohyun-chris-jeon.github.io/posts/PEFT/" rel="alternate" type="text/html" title="12-(3) PEFT가 필요한 이유는 무엇이며, 어떤 상황에서 특히 효과적인가요?" />
    <published>2025-08-29T14:00:00+09:00</published>
  
    <updated>2025-09-02T16:02:56+09:00</updated>
  
    <id>https://soohyun-chris-jeon.github.io/posts/PEFT/</id>
    <content type="text/html" src="https://soohyun-chris-jeon.github.io/posts/PEFT/" />
    <author>
      <name>soohyun-chris-jeon</name>
    </author>

  
    
    <category term="Codeit AI 3기" />
    
    <category term="Weekly Paper" />
    
  

  <summary>🟢 TBU   ⚪ TBU..  🟢 예시 답안 (코드잇 제공)    PEFT가 필요한 이유는 대형 언어 모델을 실제 환경에 맞게 활용하려고 할 때, 기존의 전체 파인튜닝 방식이 너무 비효율적이고 부담이 크기 때문입니다.기존 방식은 모델의 모든 파라미터를 다시 학습해야 하다 보니, 수많은 GPU 자원이 필요하고, 학습 시간도 오래 걸리며, 각각의 작업마다 전체 모델을 따로 저장해야 해서 저장 공간도 많이 차지합니다. 특히 사전학습 모델의 크기가 수십억에서 수천억 파라미터로 커진 요즘에는, 이 방식이 현실적으로 어렵습니다.이럴 때 PEFT는 전체 모델을 그대로 두고, 일부 파라미터만 학습하거나 작은 모듈만 추가로 학습하는 방식이기 때문에 훨씬 가볍고 빠릅니다. 전체 모델의 1%도 안 되는 파라미터만 수정하면...</summary>

  </entry>

  
  <entry>
    <title>12-(2) 모델 크기를 키우는 것만으로는 성능이 일정 시점 이후 둔화되는 이유는 무엇일까요?</title>
    <link href="https://soohyun-chris-jeon.github.io/posts/model-size/" rel="alternate" type="text/html" title="12-(2) 모델 크기를 키우는 것만으로는 성능이 일정 시점 이후 둔화되는 이유는 무엇일까요?" />
    <published>2025-08-29T13:00:00+09:00</published>
  
    <updated>2025-09-02T16:02:56+09:00</updated>
  
    <id>https://soohyun-chris-jeon.github.io/posts/model-size/</id>
    <content type="text/html" src="https://soohyun-chris-jeon.github.io/posts/model-size/" />
    <author>
      <name>soohyun-chris-jeon</name>
    </author>

  
    
    <category term="Codeit AI 3기" />
    
    <category term="Weekly Paper" />
    
  

  <summary>🟢 TBU   ⚪ TBU..  🟢 예시 답안 (코드잇 제공)          모델 크기를 키우면 초기에는 성능이 눈에 띄게 좋아지지만, 일정 규모를 넘어서면 성능 향상 속도가 점점 느려지고 결국에는 거의 개선되지 않는 구간에 도달하게 됩니다. 이 현상에는 몇 가지 이유가 있습니다.     첫째, 학습 데이터의 한계입니다. 모델이 아무리 크더라도 학습할 수 있는 데이터가 부족하거나 품질이 낮으면 그 성능은 금방 한계에 부딪힙니다. 특히 데이터에 중복이 많거나 편향된 정보가 많으면, 큰 모델일수록 오히려 그 편향을 더 강하게 반영할 수 있습니다.     둘째, 모델이 학습한 정보 중에는 실제로 문제 해결에 도움이 되지 않는 정보도 포함되기 때문에, 모델이 커질수록 반드시 ‘좋은 정보만 더 많이’ 배우는 것...</summary>

  </entry>

</feed>


