---
layout: post
title:  "9-(3) GAN에서 생성자(Generator)와 판별자(Discriminator)의 역할은 각각 무엇인가요?"
date:   2025-07-11 11:00:00 +0900
categories: [Codeit AI 3기, Weekly Paper]
tags: [GAN, PyTorch, CNN, convolutional-neural-network, Deep Learning, AI, Computer Vision]
comments: true     # 댓글 기능 사용 (옵션)
math: true  # ✅ 요거 꼭 추가!


---

### 🟢 GAN(Generative Adversarial Network)

GAN은 딥러닝 역사에서 중요한 패러다임을 제시한 네트워크이며 현재 산업에서 사용되는 generative model의 근간이 되는 수많은 이론을 탄생시킨 사건이었다.

**GAN(Generative Adversarial Network, 생성적 적대 신경망)**은 딥러닝의 대가 이안 굿펠로우(Ian Goodfellow)가 2014년에 제안한, 말 그대로 '혁명적인' 생성 모델이다. GAN의 핵심 아이디어는 두 개의 신경망, 즉 **생성자(Generator)**와 **판별자(Discriminator)**를 서로 경쟁시키면서 학습시키는 것이다.


---

#### ⚪ 1. 두 명의 플레이어: 생성자와 판별자

GAN의 구조는 이 두 플레이어의 역할로 완벽히 설명된다.

![GAN](https://www.researchgate.net/publication/356809414/figure/fig1/AS:1098577317244930@1638932651307/Example-of-GAN-Architecture.ppm)


#### ① 생성자 (Generator, G) - 위조지폐범

-   **역할**: 진짜 같은 **가짜 데이터**를 만듬.
-   **입력**: 잠재 공간(Latent Space)에서 샘플링한 간단한 **랜덤 노이즈 벡터 ($z$)**를 입력받음.
-   **출력**: 실제 데이터와 같은 형태의 **가짜 데이터 ($G(z)$)**를 출력. (e.g., 이미지)
-   **목표**: 판별자를 완벽하게 속여서, 자신이 만든 가짜 데이터를 판별자가 '진짜'라고 판단하게 만드는 것.

#### ② 판별자 (Discriminator, D) - 경찰

-   **역할**: 주어진 데이터가 **진짜인지 가짜인지** 판별.
-   **입력**: **실제 데이터셋의 진짜 데이터 ($x$)** 또는 **생성자가 만든 가짜 데이터 ($G(z)$)**를 입력받음.
-   **출력**: 입력된 데이터가 진짜일 확률을 0과 1 사이의 값으로 출력. (e.g., 1에 가까우면 진짜, 0에 가까우면 가짜)
-   **목표**: 진짜 데이터와 가짜 데이터를 최대한 정확하게 구별하는 것.

---

#### ⚪ 2. 학습 과정: 치열한 미니맥스 게임

GAN의 학습은 두 네트워크가 서로의 성능을 발판 삼아 함께 성장하는 과정입니다. 학습은 두 단계로 나뉘어 반복적으로 진행됨.

**1단계: 판별자(D) 학습**
1.  생성자(G)는 잠시 동결(freeze)시킴.
2.  실제 데이터($x$) 한 묶음과 생성자가 만든 가짜 데이터($G(z)$) 한 묶음을 판별자에 보여줌.
3.  판별자는 실제 데이터에는 1을, 가짜 데이터에는 0을 출력하도록 학습됨. 즉, **자신의 판별 능력을 최대화**하게 됨.

**2단계: 생성자(G) 학습**
1.  이번엔 판별자(D)를 동결.
2.  생성자는 새로운 가짜 데이터($G(z)$)를 만들어 판별자에게 보냄.
3.  판별자가 이 가짜 데이터에 대해 **1(진짜)을 출력하도록** 생성자를 학습. 즉, 판별자를 속이는 능력을 최대화.

이 두 단계를 수없이 반복하면, 생성자는 판별자를 속이기 위해 점점 더 현실적인 데이터를 만들고, 판별자는 더 정교한 가짜를 구별하기 위해 판별 능력을 키우게 된다. 결국, 생성된 데이터가 실제 데이터 분포에 수렴하게 됨.

---

#### ⚪ 3. GAN의 Loss 함수: 경쟁을 수학으로 표현하다

GAN의 목적은 다음의 **미니맥스(Minimax) 게임** 수식으로 표현.

$$ \min_G \max_D V(D, G) = \mathbb{E}_{x \sim p_{data}(x)}[\log D(x)] + \mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z)))] $$

조금 복잡해 보이지만, 각자의 입장에서 보면 간단함.

-   **$\max_D$ (판별자의 목표)**: 판별자는 전체 값 $V(D,G)$를 최대화하려고 함.
    -   `D(x)` (진짜 데이터에 대한 판별값)를 1에 가깝게 만들어 `log D(x)`를 최대화함.
    -   `D(G(z))` (가짜 데이터에 대한 판별값)를 0에 가깝게 만들어 `log(1 - D(G(z)))`를 최대화함.

-   **$\min_G$ (생성자의 목표)**: 생성자는 전체 값 $V(D,G)$를 최소화하려고 함.
    -   생성자는 첫 번째 항(`log D(x)`)에는 영향을 줄 수 없음.
    -   두 번째 항 `log(1 - D(G(z)))`를 최소화해야 함. 이를 위해 `D(G(z))`를 1에 가깝게, 즉 판별자가 속도록 만들어야 함.
---

#### ⚪ 4. GAN vs VAE: 생성 모델의 두가지 타입

| 구분 | **GAN (Generative Adversarial Network)** | **VAE (Variational Autoencoder)** |
| :--- | :--- | :--- |
| **구조** | 생성자-판별자 (경쟁 구조) | 인코더-디코더 (협력 구조) |
| **Loss 함수** | 적대적 손실 (Minimax Loss) | 복원 손실 + KL 발산 (정규화) |
| **생성 품질** | 매우 선명하고 현실적인 이미지 생성에 강점 | 다소 흐릿(blurry)하지만 안정적인 결과 |
| **학습 안정성**| 학습이 매우 불안정하고 튜닝이 어려움 | 상대적으로 안정적이고 수렴이 잘 됨 |
| **잠재 공간** | 명시적으로 배우지 않음 (비구조적) | 확률 분포를 명시적으로 학습 (구조적) |

---


#### ⚪ 5. GAN이 딥러닝 역사에서 가지는 의미

1. **생성 개념의 도입**: 분석 중심의 딥러닝에서 생성 중심 딥러닝으로의 패러다임 전환.
2. **Adversarial Training**의 제안: Generator와 Discriminator의 경쟁 학습 프레임워크.
3. **고품질 이미지 생성**: StyleGAN 시리즈를 통해 사진 수준의 생성 이미지 구현.
4. **다양한 응용 분야로 확장**: 예술, 의료, 시뮬레이션 등 다양한 분야에서 응용.
5. **후속 생성 모델 발전에 영향**: VAE, Diffusion Model 등과 비교 기준이 됨.
6. **이론적 논의 촉발**: 불안정한 학습, 수렴 문제 등 연구적 도전 과제 제공.

---

### 참고 자료
- **원본 논문**: Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., ... & Bengio, Y. (2014). Generative adversarial nets. *Advances in neural information processing systems*, 27.

---

### 🟢 예시 답안 (코드잇 제공)
>  - GAN(Generative Adversarial Networks)은 두 개의 신경망인 생성자(Generator)와 판별자(Discriminator)가 서로 경쟁하면서 데이터를 생성하는 모델입니다.
- 생성자(Generator)는 새로운 데이터를 만들어내는 역할을 합니다. 랜덤한 노이즈를 입력으로 받아, 실제 데이터와 구별할 수 없을 정도로 유사한 데이터를 생성하는 것이 목표입니다. 생성자는 학습을 거듭하면서 점점 더 현실적인 데이터를 만들어내도록 발전합니다.
- 반면, 판별자(Discriminator)는 입력된 데이터가 실제 데이터인지, 생성자가 만든 가짜 데이터인지 구별하는 역할을 합니다. 처음에는 가짜 데이터를 쉽게 구별할 수 있지만, 생성자가 점점 더 정교한 데이터를 만들면서 판별자의 판단이 어려워지게 됩니다.
- 이 두 네트워크는 적대적 학습(adversarial learning)을 통해 서로 경쟁하며 성능을 향상시킵니다. 생성자는 판별자를 속이기 위해 점점 더 현실적인 데이터를 만들어내려 하고, 판별자는 생성자가 만든 데이터를 더 정확하게 구별하려고 학습합니다. 결국, 이 과정이 반복되면서 생성자는 점점 더 실제 데이터와 구별하기 어려운 고품질의 데이터를 생성할 수 있게 됩니다.
