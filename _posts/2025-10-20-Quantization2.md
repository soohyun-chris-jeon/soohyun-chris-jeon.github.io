---
layout: post
title:  "15-(3) 양자화나 모델 경량화 후 실제 서비스에서 성능이 저하되지 않도록 하기 위해 어떤 테스트나 확인 절차가 필요할까요?"
date:   2025-10-20 02:00:00 +0900
categories: [Quantization]
tags: [Docker, Deep Learning, AI]
comments: true     # 댓글 기능 사용 (옵션)
# image:
#     path: https://images.velog.io/images/iuliet716/post/d2493856-7888-488b-86ad-4706406a02f7/Docker-Logo-White-RGB_Vertical-BG_0-1.png

---
## 🟢 양자화나 모델 경량화 후 실제 서비스에서 성능이 저하되지 않도록 하기 위해 어떤 테스트나 확인 절차

모델을 경량화하고 나서 "그래서 이게 실제로 잘 돌아가는 건가?"를 확인하는 과정은 필수적일 것이다.

최적화를 했는데 성능이 엉망이 되면 아무 소용이 없으니까. 양자화나 경량화 후에 서비스 성능이 저하되지 않도록 하려면, 크게 **세 가지 관점**에서 체계적인 검증이 필요하다고 한다: **1) 모델 정확도, 2) 추론 성능, 3) 실제 환경 테스트.**

---

#### ⚪ 1. 모델 정확도(Accuracy)

가장 먼저 확인해야 할 부분이다. 모델이 가벼워지는 대가로 원래의 예측 성능을 잃어버렸는지 꼼꼼히 따져봐야 한다.

* **Offline Evaluation (오프라인 평가)**:
    * **테스트 데이터셋 평가**: 원본 FP32 모델이 사용했던 것과 **동일한 테스트 데이터셋**으로 양자화된 INT8 모델의 성능(Accuracy, Precision, Recall, F1-score, mAP 등)을 측정하고 직접 비교함.
    * **평가 지표 상세 분석**: 전체 평균 점수만 보지 말고, **클래스별(per-class) 성능**을 꼭 확인해야 한다. 예를 들어, 특정 소수 클래스(minority class)에 대한 예측 성능이 유독 심하게 떨어질 수 있다. Confusion Matrix를 그려서 어떤 부분에서 오차가 발생하는지 분석하는 게 좋다.
    * **엣지 케이스(Edge Case) 테스트**: 일반적인 데이터에서는 괜찮다가도, 매우 드물거나 어려운 케이스(예: 조명이 어둡거나, 객체가 가려진 이미지)에서 성능이 급격히 저하될 수 있다. 이런 엣지 케이스 데이터들을 따로 모아서 테스트해야 한다.

> **"양자화 민감도 분석 (Quantization Sensitivity Analysis)"**
> 어떤 레이어가 양자화 때문에 성능 저하를 많이 일으키는지 분석하는 과정. 예를 들어, 특정 Convolution 레이어가 문제라면, 그 레이어만 FP16이나 FP32로 남겨두고 나머지만 INT8로 양자화하는 **혼합 정밀도(Mixed-Precision)** 전략을 사용할 수 있다.

---

#### ⚪ 2. 추론 성능(Inference Performance) 검증

모델을 경량화하는 주된 이유지. 정말로 빨라졌는지, 리소스를 적게 쓰는지 수치로 증명해야 한다.

* **속도 측정 (Latency & Throughput)**:
    * **Latency (지연 시간)**: 단일 입력에 대해 추론을 완료하는 데 걸리는 시간이야 (단위: ms). 실시간 서비스에서 사용자 경험과 직결된다. **여러 번 측정해서 평균과 편차(standard deviation)를 함께 봐야 한다.**
    * **Throughput (처리량)**: 단위 시간당 처리할 수 있는 입력의 수 (단위: FPS, RPS). 서버가 동시에 얼마나 많은 요청을 감당할 수 있는지를 나타냄.

* **리소스 사용량 측정**:
    * **메모리 사용량 (Memory Footprint)**: 모델이 로드되었을 때 RAM이나 VRAM을 얼마나 차지하는지 측정해야 해. 임베디드 기기나 모바일 환경에서는 이게 굉장히 중요하다.
    * **CPU/GPU 사용률**: 추론이 실행되는 동안의 CPU 또는 GPU 점유율을 확인해서, 다른 프로세스에 영향을 주지 않는지 확인해야 힌디.
    * **전력 소모량**: 모바일이나 엣지 디바이스에서는 배터리 수명과 직결되므로, 모델 추론 시 소모되는 전력을 측정하는 것도 중요할 수 있다.



---

#### ⚪ 3. 실제 환경(Production-like Environment) 테스트

랩실 환경과 실제 서비스 환경은 하늘과 땅 차이야. 최종 배포 환경과 최대한 유사한 곳에서 통합 테스트를 거쳐야 한다.

* **A/B 테스트**: 가장 확실한 방법. 기존 모델(A)과 경량화된 모델(B)을 동시에 서비스에 배포하고, 일부 사용자 그룹에게만 새 모델의 결과를 보여주면서 실제 서비스 지표(예: 클릭률, 구매 전환율, 사용자 만족도)에 차이가 없는지 비교하는 것. 성능 저하가 없다면 점진적으로 새 모델의 비중을 늘려가면 된다.
* **Shadow Testing (그림자 테스트)**: 새 모델을 실제 서비스 트래픽을 받도록 배포하되, 그 예측 결과를 사용자에게 보여주지는 않고 내부적으로 로깅만 하는 방식이다. 기존 모델의 예측 결과와 비교하면서, 실시간 데이터에 대해 안정적으로 동작하는지, 예상치 못한 오류는 없는지 확인하는 거지. A/B 테스트 전 단계에서 안전하게 검증하기 좋다.
* **하드웨어별 검증**: 모델이 배포될 타겟 하드웨어(예: NVIDIA Jetson, Raspberry Pi, 특정 스마트폰 모델)에서 직접 성능을 테스트해야 한다. 데스크탑 GPU에서 잘 되던 것이 엣지 디바이스에서는 아예 동작하지 않거나, 예상보다 훨씬 느릴 수 있다.


---


## 🟢 예시 답안 (코드잇 제공)


>모델을 양자화하거나 경량화한 후에는, 실제 서비스에 투입했을 때 원래 모델 대비 성능이 유지되는지를 꼭 확인해야 합니다. 이 과정을 거치지 않으면, 추론 속도는 빨라졌지만 정확도가 크게 떨어지는 문제가 생길 수 있기 때문입니다.<br>
가장 기본적인 검증 절차는 원본 모델과 최적화된 모델의 정확도나 정밀도 같은 평가 지표를 동일한 테스트 데이터셋으로 비교하는 것입니다. 예를 들어, 양자화 모델의 Top-1 accuracy가 원본 모델에 비해 몇 퍼센트 포인트 떨어졌는지 확인하고, 허용 가능한 오차 범위 내인지 판단합니다.<br>
또한 실제 서비스 환경과 유사한 조건에서 추론 속도, 메모리 사용량, GPU 활용률 등을 벤치마크 도구나 프로파일링 툴을 통해 측정합니다. 예를 들어 TensorRT를 적용했다면 trtexec 같은 도구를 이용해서 FPS나 latency를 측정할 수 있습니다.<br>
추가로, 서비스 사용자에게 영향을 줄 수 있는 부분을 검증하기 위해 A/B 테스트나 shadow testing을 통해 실제 트래픽을 흘려보며 성능 저하나 예외 상황이 없는지도 관찰합니다.<br>
이렇게 정확도, 처리 속도, 시스템 자원 사용, 실제 사용자 경험 등을 종합적으로 검증함으로써, 모델 최적화 후에도 안정적이고 신뢰할 수 있는 서비스를 제공할 수 있습니다.