---
layout: post
title:  "[Part2] 중급프로젝트 중간정리#1"
date:   2025-09-18 10:00:00 +0900
categories: [Deep Learning, LLM]
tags: [NLP, LLM, python, Deep Learning, PyTorch, numpy]
image:
  path: https://img1.daumcdn.net/thumb/R750x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F4qgsr%2FbtsFEtondnt%2FXoFKqUvKEaFyQubZZyLIPk%2Fimg.png

comments: true     # 댓글 기능 사용 (옵션)

---
# 2025.09.18 ~ present

## 🟣 데이터 처리: 전수현

## 1. 데이터 추출 파트
HWP 파일에서 깨끗한 텍스트를 안정적으로 추출하는 게 이번 데이터 처리 파트의 가장 중요하고 어려운 과정.


### 텍스트 추출 전략 수립
(1) `HWP -> HTML`: 리브레 오피스 라이브러리
(2) `HWP -> PDF`: PDF 변환 후 OCR/파서 적용
(3) 혼합 방식: 텍스트 `hwp5txt`, 테이블 `camelot`
(4) `HWP` 직접 추출: 공식 SDK / hwpctrl 활용

등.. 아이디어 수집 및 실험 필요

#### **방법 1: HWP 전문 변환기(리브레오피스) 활용**

HWP를 단순 `txt`가 아닌 `HTML`로 변환해서 구조적 정보를 최대한 살림

  * **전략:** 파이썬으로 리브레오피스(LibreOffice)를 제어해 **HWP를 HTML로 변환**한 뒤, 파이썬의 `BeautifulSoup` 라이브러리로 **HTML 구조를 분석**해 텍스트와 표를 추출.

  * **작동 방식:**

    1.  파이썬 코드가 터미널 명령어로 리브레오피스를 실행시켜 HWP 파일을 HTML 파일로 변환.
    2.  생성된 HTML 파일을 파이썬으로 읽어들임.
    3.  `BeautifulSoup`으로 HTML 태그(`<h1>`, `<p>`, `<table>` 등)를 분석.
    4.  일반 텍스트는 `<p>` 태그에서, **표 데이터는 `<table>` 태그에서 구조적으로 추출**.


    ```python
    import subprocess
    from bs4 import BeautifulSoup
    from pathlib import Path

    def hwp_to_structured_text(hwp_path: Path):
        # 1. HWP -> HTML 변환
        subprocess.run(['libreoffice', '--headless', '--convert-to', 'html', str(hwp_path)], capture_output=True)
        
        html_path = hwp_path.with_suffix('.html')
        
        if not html_path.exists():
            return "HTML 변환 실패"

        # 2. BeautifulSoup으로 HTML 파싱
        soup = BeautifulSoup(html_path.read_text(encoding='utf-8'), 'html.parser')
        
        # 3. 표(table)를 Markdown 형식으로 변환 (예시)
        for table in soup.find_all('table'):
            # ... (테이블 파싱 로직) ...
        
        # 4. 전체 텍스트 반환
        return soup.get_text()
    ```


이미지는 별도 파일로 추출되지만, 이미지 안의 텍스트(OCR)는 처리하지 못함.


#### **방법2** : TBD
추후 파트 담당과 상의 후 실험 및 개별 파일 확인 시작



## 2. 