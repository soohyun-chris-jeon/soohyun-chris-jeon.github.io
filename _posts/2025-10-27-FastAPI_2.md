---
layout: post
title:  "16-(3) 현존하는 AI 웹/앱서비스를 하나 선정하세요. (가상의 서비스로 해보는 것도 좋아요.) 그 서비스가 지금까지 학습한 Docker, 추론 최적화, Streamlit, FastAPI로 구현되었다고 가정하고, 전체 아키텍처를 작성해보세요. 만약 가능하다면, 보안 요소(CORS 등)/멀티유저 요청 처리 방안(비동기 처리, 대기 큐 등)/클라우드 배포 구조(GCP, AWS)/모니터링 및 로깅 전략 까지 포함하여 작성해보세요."
date:   2025-10-27 02:00:00 +0900
categories: [Quantization]
tags: [Docker,Streamlit, FastAPI, Deep Learning, AI]
comments: true     # 댓글 기능 사용 (옵션)
# image:
#     path: https://images.velog.io/images/iuliet716/post/d2493856-7888-488b-86ad-4706406a02f7/Docker-Logo-White-RGB_Vertical-BG_0-1.png

---
## 🟢 
---


## 🟢 예시 답안 (코드잇 제공)


>모델을 양자화하거나 경량화한 후에는, 실제 서비스에 투입했을 때 원래 모델 대비 성능이 유지되는지를 꼭 확인해야 합니다. 이 과정을 거치지 않으면, 추론 속도는 빨라졌지만 정확도가 크게 떨어지는 문제가 생길 수 있기 때문입니다.<br>
가장 기본적인 검증 절차는 원본 모델과 최적화된 모델의 정확도나 정밀도 같은 평가 지표를 동일한 테스트 데이터셋으로 비교하는 것입니다. 예를 들어, 양자화 모델의 Top-1 accuracy가 원본 모델에 비해 몇 퍼센트 포인트 떨어졌는지 확인하고, 허용 가능한 오차 범위 내인지 판단합니다.<br>
또한 실제 서비스 환경과 유사한 조건에서 추론 속도, 메모리 사용량, GPU 활용률 등을 벤치마크 도구나 프로파일링 툴을 통해 측정합니다. 예를 들어 TensorRT를 적용했다면 trtexec 같은 도구를 이용해서 FPS나 latency를 측정할 수 있습니다.<br>
추가로, 서비스 사용자에게 영향을 줄 수 있는 부분을 검증하기 위해 A/B 테스트나 shadow testing을 통해 실제 트래픽을 흘려보며 성능 저하나 예외 상황이 없는지도 관찰합니다.<br>
이렇게 정확도, 처리 속도, 시스템 자원 사용, 실제 사용자 경험 등을 종합적으로 검증함으로써, 모델 최적화 후에도 안정적이고 신뢰할 수 있는 서비스를 제공할 수 있습니다.