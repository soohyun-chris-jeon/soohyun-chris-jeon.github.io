---
layout: post
title:  "[Part 2] Study log 2025.06.09 ~ 08.14  "
date:   2025-06-09 10:00:00 +0900
categories: [Codeit AI 3ê¸°, Study log]
tags: [python, Deep Learning, PyTorch, numpy]
comments: true     # ëŒ“ê¸€ ê¸°ëŠ¥ ì‚¬ìš© (ì˜µì…˜)

---



![ì½”ë“œì‡ ìŠ¤í”„ë¦°íŠ¸](https://img1.daumcdn.net/thumb/R750x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F4qgsr%2FbtsFEtondnt%2FXoFKqUvKEaFyQubZZyLIPk%2Fimg.png)

# ğŸŸ£ 2025.06.09 ~ 2025.08.14ì˜ ê¸°ë¡ 


## 2025-06-09 Mon
#### ğŸŸ¡ Gitì€ íŒŒì¼ ì‹œìŠ¤í…œ ë³€í™”ë¥¼ ê°ì§€í•˜ê¸´ í•˜ì§€ë§Œ, ì¶”ì í•˜ì§€ëŠ” ì•ŠìŒ

- Gitì—ì„œ "ê°ì§€"ì™€ "ì¶”ì "ì˜ ì°¨ì´

### ğŸ” ì˜ë¯¸ ë¶„ì„
- **ê°ì§€(detect)**: `git status` ëª…ë ¹ìœ¼ë¡œ ìƒˆ íŒŒì¼ì´ë‚˜ ìˆ˜ì •ëœ íŒŒì¼ì„ ë³´ì—¬ì¤„ ìˆ˜ ìˆìŒ
- **ì¶”ì (tracked)**: Gitì´ í•´ë‹¹ íŒŒì¼ì„ ë²„ì „ ê´€ë¦¬ ëŒ€ìƒìœ¼ë¡œ ì‚¼ëŠ” ê²ƒ (ì»¤ë°‹ì— í¬í•¨ë  ìˆ˜ ìˆìŒ)


| ì‘ì—…    | Gitì´ í•˜ëŠ” ì¼   | ìš°ë¦¬ê°€ í•´ì•¼ í•  ì¼                                        |
| ----- | ----------- | ------------------------------------------------- |
| íŒŒì¼ ìˆ˜ì • | ë³€ê²½ì‚¬í•­ ê°ì§€     | `git add`ë¡œ staged                                 |
| íŒŒì¼ ì¶”ê°€ | ìƒˆ íŒŒì¼ ê°ì§€     | `git add ìƒˆíŒŒì¼`                                     |
| íŒŒì¼ ì‚­ì œ | ì‚­ì œ ê°ì§€       | `git rm ì‚­ì œëœíŒŒì¼`                                    |
| íŒŒì¼ ì´ë™ | ì‚­ì œ + ì¶”ê°€ë¡œ ì¸ì‹ | `git mv ì›ë˜ê²½ë¡œ ìƒˆê²½ë¡œ` ë˜ëŠ” `git add ìƒˆíŒŒì¼ && git rm ì›ë˜íŒŒì¼` |

```bash
git add test.txt  # test.txtëŠ” staged ìƒíƒœ
git status 
git commit ...  # commitìœ¼ë¡œ tracked ìƒíƒœ
```


- `git status`ë¥¼ í•­ìƒ ì£¼ì‹œí•˜ë©´ ë¬´ìŠ¨ ì¼ì´ ë²Œì–´ì¡ŒëŠ”ì§€ ì •í™•í•˜ê²Œ ì•Œ ìˆ˜ ìˆë‹¤.

- `Staged`ëŠ” ì»¤ë°‹í•˜ê¸° ì „ì— ë³€ê²½ ì‚¬í•­ì„ ì„ì‹œ ì €ì¥í•˜ëŠ” ìƒíƒœ


## 2025-06-10 Tue
#### `np.unique`


## 2025-06-11 Wed
#### âšª `torch.Tensor` vs `np.array`  
| ìš”ì•½    | ë‚´ìš©                                               |
| ----- | ------------------------------------------------ |
| ê³µí†µì    | ë‹¤ì°¨ì› ë°°ì—´, ë²¡í„°í™”, ë¸Œë¡œë“œìºìŠ¤íŒ…, dtype ì„¤ì •, ì„œë¡œ ë³€í™˜ ê°€ëŠ¥          |
| ì°¨ì´ì    | **PyTorchëŠ” autograd + GPU ì§€ì›**, NumPyëŠ” ì¼ë°˜ ìˆ˜ì¹˜ ê³„ì‚°ìš© |
| ì‹¤ì „ ì‚¬ìš© | ë”¥ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµì‹œ `torch.Tensor` ì¨ì•¼ í•¨                 |

- torch.tensfor()
```py
print(f'data type: {tensor.dtype}')
print(f'number of dimensions: {tensor.ndim}') # []ì˜ ìˆ˜ë¡œ í‘œí˜„í•˜ë©´ ì‰¬ì›€
print(f'shape: {tensor.shape}') 
print(f'size: {tensor.size()}') # shapeì´ë‚˜ sizeë‚˜ ê°™ìŒ
```

- `torch.tensor` vs. `torch.from_numpy()`

`torch.from_numpy()`ëŠ” ë©”ëª¨ë¦¬ë¥¼ ê³µìœ â—í•˜ë‹ˆ ì£¼ì˜!

- `torch.rand(2, 3)` : 0~1 ì‚¬ì´ì—ì„œ ê· ë“± ë¶„í¬
- `torch.randn(2, 3)` : ì •ê·œë¶„í¬ì—ì„œ ê°’ ì¶”ì¶œ
- `torch.zeros(2, 3)` : 0ìœ¼ë¡œ ì±„ì›€
- `torch.ones(2, 3)` : 1ë¡œ ì±„ì›€
- `torch.full((2, 3), 7)` : íŠ¹ì • ê°’(7)ë¡œ ì±„ì›€


#### âšª ë”¥ëŸ¬ë‹ ëª¨ë¸ë§ ì‹œ ê³ ë ¤í•  ì‚¬í•­:
1) Batch size
2) Learning rate
3) epoch



## 2025-06-12 Thu

#### ğŸ”´ Denoising Dirty Documents ë°ì´í„°ì…‹(Kaggle)
[Denoising Dirty Documents](https://www.kaggle.com/competitions/denoising-dirty-documents)

- Denoising-AE ê³¼ì œ

## 2025-06-13 Fri
#### âšª í™œì„±í™” í•¨ìˆ˜(activation function)
1) Sigmoid: ì´ˆê¸° ì‹ ê²½ë§. gradient ì†Œì‹¤ ë¬¸ì œê°€ ìˆìŒ
2) Tanh: ì‹œê·¸ëª¨ì´ë“œì˜ ë³€í˜•. ì—¬ì „íˆ gradient vanishing ë¬¸ì œê°€ ìˆìŒ
3) ReLU: í˜„ëŒ€ ì‹ ê²½ë§ì—ì„œ ê°€ì¥ ì¸ê¸° ìˆìŒ. gradientì˜ ê°ì†Œê°€ ì—†ì–´ì„œ ì†Œì‹¤ ë¬¸ì œê°€ í•´ê²°ë¨
4) Leaky ReLU: 


## 2025-06-16 Mon
#### âšª `torchvision.transforms` 

#### âšª Gradient descent
1) Batch Gradient Descent: ì „ì²´ batch_size. ê³„ì‚° ë¹„ìš© ë§¤ìš° ë†’ë‹¤
2) Stochastric Gradient Descent: ë¬´ì‘ìœ„ë¡œ 1ê°œì˜ ìƒ˜í”Œ(batch_size=1). í•™ìŠµì´ ë¶ˆì•ˆì •. 
3) Minibatch Gradient Descentâ­: mini-batchë¡œ í•™ìŠµ. ê°€ì¥ ë§ì´ ì“°ì„. ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±

## 2025-06-17 Tue
#### âšª ë¡œì»¬ ì „ìš© WSL ì„œë²„ êµ¬ì¶•í•˜ê¸°

#### âšª ë‹¤ì–‘í•œ optimizer
 - Momentum: ì´ì „ ìŠ¤í…ì— ëŒ€í•œ í•™ìŠµë¥  ê³ ë ¤
 - Adagrad: ê° ë§¤ê°œë³€ìˆ˜ì— ëŒ€í•´ í•™ìŠµë¥ ì„ ë™ì ìœ¼ë¡œ ë³€ê²½
 - RMSProp: ê³¼ê±°ì˜ ê¸°ìš¸ê¸°ëŠ” ì¡°ê¸ˆë§Œ ë°˜ì˜í•˜ê³ , ìµœì‹ ì˜ ê¸°ìš¸ê¸°ë¥¼ ë§ì´ ë°˜ì˜
 - Adamâ­: ê°€ì¥ ë³´í¸ì ìœ¼ë¡œ ì“°ì„. ëª¨ë©˜í…€ ê¸°ë°˜ê³¼ RMSPropì˜ ë°©ë²•ì„ ì ˆì¶© 



## 2025-06-18 Wed
#### .gitignore
#### âšª Normalization ê¸°ë²•
- ë°ì´í„°ì˜ ë²”ìœ„ë¥¼ ì¼ì •í•˜ê²Œ ì¡°ì •í•˜ê±°ë‚˜ ë°ì´í„°ì˜ ë¶„í¬ë¥¼ í‘œì¤€í™”í•˜ëŠ” ê³¼ì •
- ëª¨ë¸ì´ local minimaì— ê°‡íˆëŠ” ë¬¸ì œë¥¼ ì™„í™”
- í•™ìŠµì„ ë” ì•ˆì •ì ì´ê³  ë¹ ë¥´ê²Œ ì§„í–‰ë˜ë„ë¡ í•¨
- ì…ë ¥ì˜ ë¶„í¬ê°€ ê° ì¸µì„ ì§€ë‚  ë•Œë§ˆë‹¤ ì¼ì •í•˜ê²Œ ìœ ì§€ë˜ë„ë¡ í•¨
- Batch Normalizationâ­: ë„¤íŠ¸ì›Œí¬ì˜ ê° ì¸µì—ì„œ í™œì„±í™” í•¨ìˆ˜ê°€ ì…ë ¥ ë°›ëŠ” ê°’ì„ ì •ê·œí™”
  * ê° ë ˆì´ì–´ë¥¼ ê±°ì¹˜ë©° ë°œìƒí•  ìˆ˜ ìˆëŠ” ì…ë ¥ê°’ì˜ ë³€ë™ì„ íš¨ê³¼ì ìœ¼ë¡œ ì œì–´
  * ê²°ê³¼ì ìœ¼ë¡œ í•™ìŠµ ì†ë„ë¥¼ ë†’ì´ë©° ë” ì•ˆì •ì ì¸ í•™ìŠµì´ ê°€ëŠ¥
  * ê·¸ë˜ë””ì–¸íŠ¸ ì†Œì‹¤, í­ë°œ ë¬¸ì œë¥¼ ì™„í™”

  #### âšª Regualization ê¸°ë²•
- ëª¨ë¸ì´ í›ˆë ¨ë°ì´í„°ì— ê³¼ì í•©ë˜ì§€ ì•Šê³  ì¼ë°˜í™” ì„±ëŠ¥ì„ ëŒì–´ì˜¬ë¦¬ëŠ” ë°©ì‹
1) L1 ì •ê·œí™”
2) Dropout â­
3) Early Stopping â­  
4) Data Augmentation â­â­â­

## 2025-06-19 Thu
#### âšª Data Augmentation: ë°ì´í„° ì¦ê°•
- ë‹¤ì–‘í•œ í›ˆë ¨ ìƒ˜í”Œì„ ìƒì„±í•´ í•™ìŠµ íš¨ìœ¨ì„ ì¦ê°€
- ë°ì´í„° ë¶ˆê· í˜• ë¬¸ì œ í•´ê²°
- ì´ë¯¸ì§€ rotation, crop, scaling ë“±...

## 2025-06-20 Fri
#### âšª torch.utils.dataì˜ Dataset í´ë˜ìŠ¤(ì‚¬ìš©ì ì •ì˜ í´ë˜ìŠ¤) (From [íŒŒì´í† ì¹˜ ê³µì‹ë¬¸ì„œ](https://tutorials.pytorch.kr/beginner/basics/data_tutorial.html) )
- __init__, __len__, and __getitem__  3ê°€ì§€ ë©”ì„œë“œë¥¼ ë°˜ë“œì‹œ ì •ì˜í•´ì•¼í•œë‹¤.
  - **\__init__** í•¨ìˆ˜ëŠ” Dataset ê°ì²´ê°€ ìƒì„±(instantiate)ë  ë•Œ í•œ ë²ˆë§Œ ì‹¤í–‰ë©ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” ì´ë¯¸ì§€ì™€ ì£¼ì„ íŒŒì¼(annotation_file)ì´ í¬í•¨ëœ ë””ë ‰í† ë¦¬ì™€ (ë‹¤ìŒ ì¥ì—ì„œ ìì„¸íˆ ì‚´í´ë³¼) ë‘ê°€ì§€ ë³€í˜•(transform)ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
  
  - **\__len__** í•¨ìˆ˜ëŠ” ë°ì´í„°ì…‹ì˜ ìƒ˜í”Œ ê°œìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

  - **\__getitem__** í•¨ìˆ˜ëŠ” ì£¼ì–´ì§„ ì¸ë±ìŠ¤ idx ì— í•´ë‹¹í•˜ëŠ” ìƒ˜í”Œì„ ë°ì´í„°ì…‹ì—ì„œ ë¶ˆëŸ¬ì˜¤ê³  ë°˜í™˜í•©ë‹ˆë‹¤. ì¸ë±ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ, ë””ìŠ¤í¬ì—ì„œ ì´ë¯¸ì§€ì˜ ìœ„ì¹˜ë¥¼ ì‹ë³„í•˜ê³ , read_image ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë³€í™˜í•˜ê³ , self.img_labels ì˜ csv ë°ì´í„°ë¡œë¶€í„° í•´ë‹¹í•˜ëŠ” ì •ë‹µ(label)ì„ ê°€ì ¸ì˜¤ê³ , (í•´ë‹¹í•˜ëŠ” ê²½ìš°) ë³€í˜•(transform) í•¨ìˆ˜ë“¤ì„ í˜¸ì¶œí•œ ë’¤, í…ì„œ ì´ë¯¸ì§€ì™€ ë¼ë²¨ì„ Python ì‚¬ì „(dict)í˜•ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.

#### âšª torchì˜ ë¸Œë¡œë“œìºìŠ¤íŒ…ì´ë€?
- torch í•©: `+` ì—°ì‚°ì
  torch ê³±: `@`(ë§¤íŠ¸ë¦­ìŠ¤ê³±) vs. `*`(ìŠ¤ì¹¼ë¼ê³±)

- tensorì˜ sizeê°€ ë‹¬ë¼ë„ ì—°ì‚°ì´ ê°€ëŠ¥í•˜ê²Œë” êµ¬í˜„í•´ë†“ìŒ
```py
a = torch.tensor(
    [
        [1, 2, 3],
        [4, 5, 6],
    ]
)
b = torch.tensor(
    [1, -1, 2],
)

a + b 
"""
ê²°ê³¼ëŠ”
tensor([[2, 1, 5],
        [5, 4, 8]]) aì˜ ê° í–‰ì— bê°€ ë” í•´ì§
""" 
```
- ê·¸ëŸ¬ë‚˜ ëª¨ë“  tensorì— ì ìš©ë˜ëŠ” ê²ƒì€ ì•„ë‹ˆê³  ê° ë²¡í„°ì˜ lengthê°€ ë‹¤ë¥´ë©´ ë¸Œë¡œë“œìºìŠ¤íŒ…ì´ ë¶ˆê°€ëŠ¥!


#### âšª nn.Conv2d()ì— padding ê°’ì„ '`valid`'ë‚˜ '`same`'ìœ¼ë¡œ í•  ë•Œ ê°ê° íŒ¨ë”©ì´ ì–´ë–»ê²Œ ì ìš©ë˜ëŠ”ì§€
- `valid`ëŠ” paddingì„ ë”°ë¡œ ì£¼ì§€ ì•Šê³  input image ìì²´ë§Œì„ ì´ìš©í•´ convolution ì—°ì‚°ì„ ìˆ˜í–‰í•œë‹¤.
- `same`ì€ output sizeê°€ input sizeì™€ ë™ì¼í•˜ê²Œ ë˜ë„ë¡ paddingì„ ì¡°ì ˆí•œë‹¤. ë§Œì•½ stride=1, dilation=1ì¸ ê²½ìš° padding=(kernel_size-1)/2ë¡œ ì„¤ì •ëœë‹¤.

## 2025-06-23 Mon
#### âšª ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ ìµœì í™”ê°€ ì–´ë ¤ìš´ ì´ìœ 
1) ëª¨ë¸ì˜ ë¹„ì„ í˜•ì„±: ì†ì‹¤ í•¨ìˆ˜ì˜ í‘œë©´ì„ ë³µì¡í•˜ê²Œ ë§Œë“¤ì–´ Global Minimaë¥¼ ì°¾ê¸° ì–´ë µê²Œ í•¨.
2) ê³ ì°¨ì›ì„±ê³¼ ê³¼ì í•©: ê³¼ì í•© ë¬¸ì œë¥¼ ìœ„í•´ì„œ ë‹¤ì–‘í•œ ê¸°ë²• ì‚¬ìš©í•´ì•¼í•¨
3) gradient ì†Œì‹¤ ë¬¸ì œ
4) hyper parameterì˜ ë¯¼ê°ì„±

> GPT3ì˜ num of parameter: 1,750ì–µ ê°œ;;


#### âšª torch.tensorì˜ shape ë°”ê¾¸ê¸°
- `torch.reshape()`: torch.reshape(-1)
- `torch.permute()` í…ì„œ ì°¨ì› ë°”ê¾¸ê¸°
- `torch.squeeze()`: ì°¨ì›ì´ 1ì¸ ê²ƒ ì—†ì• ê¸° <-> torch.unsqueeze()


#### âšª torchì˜ `view()` vs. `reshape()`
- `reshape()`ì€ ê¸°ë³¸ì ìœ¼ë¡œ copyâ­ê°€ ì¼ì–´ë‚¨. ì›ë³¸ì—” ì˜í–¥ x
- ë©”ëª¨ë¦¬ì˜ ì—°ì†ì„±(contiguous) ê°œë…



## 2025-06-24 Tue



#### ğŸ”´ [Chest X-Ray Images (Pneumonia)](https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia) ë°ì´í„°ì…‹


## 2025-06-25 Wed
#### ğŸ”´ CaliforniaHousingDataset

## 2025-06-26 Thu
#### âšª

## 2025-06-27 Fri
#### âšª