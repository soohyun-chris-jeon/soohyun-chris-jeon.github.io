---
layout: post
title:  "12-(3) PEFT가 필요한 이유는 무엇이며, 어떤 상황에서 특히 효과적인가요?"
date:   2025-08-29 14:00:00 +0900
categories: [Codeit AI 3기, Weekly Paper]
tags: [PEFT, BERT, GPT, NLP, LLM, Trasnformer, Deep Learning, AI]
comments: true     # 댓글 기능 사용 (옵션)
image:
    path: https://d3lkc3n5th01x7.cloudfront.net/wp-content/uploads/2023/05/15213322/Parameter-efficient-Fine-tuning.png
---


## 🟢 PEFT가 필요한 이유는 무엇이며, 어떤 상황에서 특히 효과적인가요?

모델과 데이터의 크기가 커지면서 모델 전체를 처음부터 학습시키는 것보다 사전 학습된(pre-trained) 모델을 활용하는 빈도가 훨씬 더 많아지고 있다.

특히 트랜스포머와 같은 모델의 경우는 학습의 난이도가 높기 때문에 기본적으로 pre-trained 모델을 활용하는 것이 정석에 모든 딥러닝 분야에서 가까운 접근 방식이다.

LLM에서 PEFT(Parameter-Efficient Fine-Tuning)는 기법이 요즘 자주 등장하는데 PEFT는 전체 모델의 극히 일부 파라미터만 수정하여 **자원 소모를 극적으로 줄이면서도, 전체를 파인튜닝한 것과 유사한 성능**을 내는 기법이라고 한다.

수십억 개가 넘는 파라미터를 가진 거대 언어 모델(LLM) 전체를 파인튜닝하는 것이 **엄청난 비용과 시간을 필요**로 하기 때문에 정교한 파인튜닝 기법이 필요하며 아마도 계속해서 발전할 기법이 아닐까 싶다.



---
#### ⚪ 왜 PEFT가 필요한가?

LLM을 특정 작업에 맞게 조정하는 기존의 '전체 파인튜닝(Full Fine-tuning)' 방식은 다음과 같은 심각한 문제점을 가집니다.

1.  **엄청난 컴퓨팅 비용**: 수십억, 수천억 개의 파라미터 전체를 업데이트하려면 최상급 GPU 수십, 수백 대와 오랜 학습 시간이 필요합니다. 이는 개인이나 소규모 팀에게는 거의 불가능한 수준의 비용입니다.
2.  **막대한 저장 공간**: 만약 10개의 다른 작업에 모델을 적용하고 싶다면, 원본 모델(수백 GB) 크기의 모델 10개를 별도로 저장해야 합니다. 이는 매우 비효율적인 저장 공간 낭비입니다.
3.  **파국적 망각 (Catastrophic Forgetting)**: 새로운 작업을 학습하면서 기존에 모델이 가지고 있던 일반적인 지식이나 다른 작업 수행 능력을 잃어버릴 위험이 있습니다.

PEFT는 이러한 문제에 대한 아주 효과적인 해결책입니다. 모델의 99.9% 파라미터는 **'얼려서(freeze)'** 그대로 두고, **작업별로 0.1% 내외의 작은 추가 파라미터(어댑터 등)만 학습**시킵니다. 이 작은 어댑터(수십 MB)만 교체하면 원본 모델 하나로 여러 작업을 수행할 수 있습니다.

![Finetuning](https://blogs.debutinfotech.com/wp-content/uploads/2024/03/Fine-Tuning-And-PEFT.jpg)

---

#### ⚪ PEFT가 특히 효과적인 상황

##### **1. 제한된 컴퓨팅 자원 및 예산 💻**

개인 개발자, 학생, 스타트업 등 고사양 GPU 클러스터를 사용하기 어려운 환경에서 PEFT는 필수적입니다. 단일 소비자용 GPU로도 수백억 파라미터 모델을 특정 작업에 맞게 파인튜닝할 수 있게 해줍니다.

---

##### **2. 하나의 모델로 여러 작업을 수행해야 할 때 🚀**

하나의 거대 원본 모델을 유지하면서, 여러 고객사나 다양한 서비스에 맞는 **'작업별 맞춤 모듈'**을 빠르고 가볍게 만들어야 할 때 매우 효과적입니다. 예를 들어, 기본 LLM은 하나 두고 '법률 상담용 어댑터', '의료 차트 요약용 어댑터', '고객 서비스 챗봇용 어댑터' 등을 각각 수십 MB 크기로 만들어 필요에 따라 교체하며 사용할 수 있습니다. 이는 모델 관리와 배포를 훨씬 효율적으로 만듭니다.

---

##### **3. 빠른 실험과 반복이 필요할 때**

전체 파인튜닝이 몇 주에서 몇 달이 걸릴 수 있는 반면, PEFT는 훨씬 적은 파라미터를 학습시키므로 학습 시간이 크게 단축됩니다. 따라서 다양한 데이터셋이나 하이퍼파라미터로 여러 가지 아이디어를 신속하게 테스트하고 모델을 개선해 나가는 연구 및 개발 환경에 매우 적합합니다.

---

##### **4. 데이터가 많지 않을 때**

전체 파라미터를 학습시키기에는 데이터가 부족한 경우, 전체 파인튜닝은 모델이 데이터에 과적합(overfitting)될 위험이 큽니다. PEFT는 학습 대상 파라미터 수가 매우 적기 때문에, 상대적으로 적은 양의 데이터로도 과적합 위험을 줄이면서 효과적으로 모델을 특정 작업에 적응시킬 수 있습니다.





## 🟢 예시 답안 (코드잇 제공)
> PEFT가 필요한 이유는 대형 언어 모델을 실제 환경에 맞게 활용하려고 할 때, 기존의 전체 파인튜닝 방식이 너무 비효율적이고 부담이 크기 때문입니다.<br>기존 방식은 모델의 모든 파라미터를 다시 학습해야 하다 보니, 수많은 GPU 자원이 필요하고, 학습 시간도 오래 걸리며, 각각의 작업마다 전체 모델을 따로 저장해야 해서 저장 공간도 많이 차지합니다. 특히 사전학습 모델의 크기가 수십억에서 수천억 파라미터로 커진 요즘에는, 이 방식이 현실적으로 어렵습니다.<br>이럴 때 PEFT는 전체 모델을 그대로 두고, 일부 파라미터만 학습하거나 작은 모듈만 추가로 학습하는 방식이기 때문에 훨씬 가볍고 빠릅니다. 전체 모델의 1%도 안 되는 파라미터만 수정하면 되니까, 자원이 적은 환경에서도 쉽게 사용할 수 있습니다.<br><br>PEFT가 특히 효과적인 상황은 다음과 같습니다.<br><br>첫째, 하나의 모델을 다양한 작업에 재활용해야 할 때입니다. 예를 들어 챗봇, 문서 분류, 질의응답 같은 여러 태스크를 동시에 다뤄야 하는 경우, 각각을 위해 전체 모델을 다시 학습하는 것보다, 작은 파인튜닝 모듈만 따로 관리하는 방식이 훨씬 효율적입니다.<br>둘째, 빠르게 실험하고 반복해야 하는 환경에서도 유리합니다. 전체 모델을 학습하는 데 며칠씩 걸리는 대신, PEFT는 몇 시간 내에 끝날 수 있어 연구 속도와 반복 실험 속도를 크게 높일 수 있습니다.<br>셋째, 모델을 클라우드가 아닌 로컬, 모바일, 엣지 환경에서 돌려야 할 때도 좋습니다. 작은 모듈만 추가하면 되기 때문에, 저장 용량도 적고 실행 속도도 빠르기 때문입니다.<br><br>결국 PEFT는 자원을 절약하면서도 높은 성능을 유지하고, 다양한 환경에서 유연하게 모델을 활용할 수 있게 해주는 현실적인 해결책입니다.